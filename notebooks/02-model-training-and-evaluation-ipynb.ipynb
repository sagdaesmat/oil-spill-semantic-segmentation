{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14292954,"sourceType":"datasetVersion","datasetId":9123629},{"sourceId":14310769,"sourceType":"datasetVersion","datasetId":9135818},{"sourceId":14310783,"sourceType":"datasetVersion","datasetId":9135828},{"sourceId":14310802,"sourceType":"datasetVersion","datasetId":9135842},{"sourceId":14310956,"sourceType":"datasetVersion","datasetId":9135953},{"sourceId":14325895,"sourceType":"datasetVersion","datasetId":9145698},{"sourceId":14325907,"sourceType":"datasetVersion","datasetId":9145704},{"sourceId":14325970,"sourceType":"datasetVersion","datasetId":9145743}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Oil Spill Detection – Model Training & Evaluation\n\nThis notebook covers:\n- Model architecture design\n- Custom attention modules\n- Training loop\n- Validation & testing\n- mIoU and per-class IoU evaluation\n\nThe model is trained for semantic segmentation of oil spill phenomena in aerial imagery.\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom tqdm import tqdm\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", DEVICE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:41.600388Z","iopub.execute_input":"2025-12-29T10:58:41.600734Z","iopub.status.idle":"2025-12-29T10:58:44.782458Z","shell.execute_reply.started":"2025-12-29T10:58:41.600710Z","shell.execute_reply":"2025-12-29T10:58:44.781848Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Attention Modules (Implemented from Scratch)\n\nWe implement Channel Attention and Spatial Attention modules\nto enhance feature representation, especially for:\n- Thin oil sheens\n- Small objects (ships, platforms)\n","metadata":{}},{"cell_type":"code","source":"class ChannelAttention(nn.Module):\n    def __init__(self, in_channels, reduction=16):\n        super().__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n\n        self.fc = nn.Sequential(\n            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n            nn.ReLU(),\n            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n        )\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg = self.fc(self.avg_pool(x))\n        max_ = self.fc(self.max_pool(x))\n        return x * self.sigmoid(avg + max_)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:44.783225Z","iopub.execute_input":"2025-12-29T10:58:44.783606Z","iopub.status.idle":"2025-12-29T10:58:44.788723Z","shell.execute_reply.started":"2025-12-29T10:58:44.783581Z","shell.execute_reply":"2025-12-29T10:58:44.788015Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class SpatialAttention(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg = torch.mean(x, dim=1, keepdim=True)\n        max_, _ = torch.max(x, dim=1, keepdim=True)\n        attn = torch.cat([avg, max_], dim=1)\n        return x * self.sigmoid(self.conv(attn))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:44.790478Z","iopub.execute_input":"2025-12-29T10:58:44.790743Z","iopub.status.idle":"2025-12-29T10:58:44.808168Z","shell.execute_reply.started":"2025-12-29T10:58:44.790722Z","shell.execute_reply":"2025-12-29T10:58:44.807632Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Encoder: Modified ResNet-50 Backbone\n\n- Pretrained on ImageNet\n- Used as feature extractor\n- Outputs multi-scale feature maps\n","metadata":{}},{"cell_type":"code","source":"class ResNetEncoder(nn.Module):\n    def __init__(self):\n        super().__init__()\n        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n\n        self.stage0 = nn.Sequential(\n            backbone.conv1,\n            backbone.bn1,\n            backbone.relu,\n            backbone.maxpool\n        )\n        self.stage1 = backbone.layer1   # 256\n        self.stage2 = backbone.layer2   # 512\n        self.stage3 = backbone.layer3   # 1024\n        self.stage4 = backbone.layer4   # 2048\n\n    def forward(self, x):\n        x0 = self.stage0(x)\n        x1 = self.stage1(x0)\n        x2 = self.stage2(x1)\n        x3 = self.stage3(x2)\n        x4 = self.stage4(x3)\n        return x1, x2, x3, x4\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:44.808927Z","iopub.execute_input":"2025-12-29T10:58:44.809474Z","iopub.status.idle":"2025-12-29T10:58:44.820265Z","shell.execute_reply.started":"2025-12-29T10:58:44.809452Z","shell.execute_reply":"2025-12-29T10:58:44.819656Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Decoder Blocks with Attention\n","metadata":{}},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n            nn.BatchNorm2d(out_ch),\n            nn.ReLU(inplace=True),\n        )\n        self.ca = ChannelAttention(out_ch)\n        self.sa = SpatialAttention()\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.ca(x)\n        x = self.sa(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:44.820988Z","iopub.execute_input":"2025-12-29T10:58:44.821230Z","iopub.status.idle":"2025-12-29T10:58:44.835711Z","shell.execute_reply.started":"2025-12-29T10:58:44.821196Z","shell.execute_reply":"2025-12-29T10:58:44.835120Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Full Model Architecture – OilSpillNet\n","metadata":{}},{"cell_type":"code","source":"class OilSpillNet(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.encoder = ResNetEncoder()\n\n        self.dec4 = DecoderBlock(2048, 512)\n        self.dec3 = DecoderBlock(1024 + 512, 256)\n        self.dec2 = DecoderBlock(512 + 256, 128)\n        self.dec1 = DecoderBlock(256 + 128, 64)\n\n        self.final = nn.Conv2d(64, num_classes, kernel_size=1)\n\n    def forward(self, x):\n        x1, x2, x3, x4 = self.encoder(x)\n\n        d4 = F.interpolate(self.dec4(x4), size=x3.shape[2:], mode=\"bilinear\", align_corners=False)\n        d3 = F.interpolate(self.dec3(torch.cat([x3, d4], dim=1)), size=x2.shape[2:], mode=\"bilinear\", align_corners=False)\n        d2 = F.interpolate(self.dec2(torch.cat([x2, d3], dim=1)), size=x1.shape[2:], mode=\"bilinear\", align_corners=False)\n        d1 = self.dec1(torch.cat([x1, d2], dim=1))\n\n        out = self.final(F.interpolate(d1, size=x.shape[2:], mode=\"bilinear\", align_corners=False))\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:44.836396Z","iopub.execute_input":"2025-12-29T10:58:44.836584Z","iopub.status.idle":"2025-12-29T10:58:44.850656Z","shell.execute_reply.started":"2025-12-29T10:58:44.836566Z","shell.execute_reply":"2025-12-29T10:58:44.850168Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Loss Functions\n- Cross Entropy (class-weighted)\n- Dice Loss (overlap-focused)\n","metadata":{}},{"cell_type":"code","source":"class DiceLoss(nn.Module):\n    def __init__(self, smooth=1):\n        super().__init__()\n        self.smooth = smooth\n\n    def forward(self, preds, targets):\n        preds = F.softmax(preds, dim=1)\n        targets_oh = F.one_hot(targets, NUM_CLASSES).permute(0,3,1,2)\n\n        intersection = (preds * targets_oh).sum(dim=(2,3))\n        union = preds.sum(dim=(2,3)) + targets_oh.sum(dim=(2,3))\n        dice = (2 * intersection + self.smooth) / (union + self.smooth)\n        return 1 - dice.mean()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:44.851388Z","iopub.execute_input":"2025-12-29T10:58:44.851565Z","iopub.status.idle":"2025-12-29T10:58:44.862326Z","shell.execute_reply.started":"2025-12-29T10:58:44.851547Z","shell.execute_reply":"2025-12-29T10:58:44.861693Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"ce_loss   = nn.CrossEntropyLoss(weight=class_weights.to(DEVICE))\ndice_loss = DiceLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:44.863055Z","iopub.execute_input":"2025-12-29T10:58:44.863371Z","iopub.status.idle":"2025-12-29T10:58:45.023382Z","shell.execute_reply.started":"2025-12-29T10:58:44.863347Z","shell.execute_reply":"2025-12-29T10:58:45.022773Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Metrics: mIoU\n","metadata":{}},{"cell_type":"code","source":"def compute_miou(pred, target):\n    ious = []\n    for cls in range(NUM_CLASSES):\n        inter = ((pred==cls)&(target==cls)).sum()\n        union = (pred==cls).sum() + (target==cls).sum() - inter\n        if union > 0:\n            ious.append(inter.float()/union.float())\n    return torch.mean(torch.stack(ious))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:45.025821Z","iopub.execute_input":"2025-12-29T10:58:45.026057Z","iopub.status.idle":"2025-12-29T10:58:45.030492Z","shell.execute_reply.started":"2025-12-29T10:58:45.026035Z","shell.execute_reply":"2025-12-29T10:58:45.029911Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def compute_miou_batch(outputs, masks, num_classes):\n    \"\"\"\n    outputs: Tensor [B, C, H, W]\n    masks:   Tensor [B, H, W]\n    return:  scalar mIoU for the batch\n    \"\"\"\n    preds = torch.argmax(outputs, dim=1)  # [B, H, W]\n\n    ious = []\n\n    for cls in range(num_classes):\n        pred_i = (preds == cls)\n        mask_i = (masks == cls)\n\n        intersection = (pred_i & mask_i).sum(dim=(1, 2)).float()\n        union = pred_i.sum(dim=(1, 2)).float() + mask_i.sum(dim=(1, 2)).float() - intersection\n\n        valid = union > 0\n        if valid.sum() > 0:\n            ious.append((intersection[valid] / union[valid]).mean())\n\n    if len(ious) == 0:\n        return torch.tensor(0.0, device=outputs.device)\n\n    return torch.mean(torch.stack(ious))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:45.031234Z","iopub.execute_input":"2025-12-29T10:58:45.031466Z","iopub.status.idle":"2025-12-29T10:58:45.044248Z","shell.execute_reply.started":"2025-12-29T10:58:45.031446Z","shell.execute_reply":"2025-12-29T10:58:45.043707Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Training Configuration\n","metadata":{}},{"cell_type":"code","source":"# ===============================\n# FINAL TRAINING + EARLY STOPPING\n# ===============================\n\nmodel = OilSpillNet(NUM_CLASSES).to(DEVICE)\n\noptimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=3e-4,\n    weight_decay=1e-4\n)\n\n# LR Scheduler (compatible with Kaggle PyTorch)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=\"max\",\n    factor=0.5,\n    patience=2\n)\n\nnum_epochs = 50\nbest_miou = 0.0\npatience = 5\nepochs_no_improve = 0\n\nfor epoch in range(num_epochs):\n    # -------- TRAIN --------\n    model.train()\n    train_loss = 0.0\n\n    for imgs, masks in train_loader:\n        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n\n        loss = ce_loss(outputs, masks) + dice_loss(outputs, masks)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    train_loss /= len(train_loader)\n\n    # -------- VALIDATION --------\n    model.eval()\n    val_miou = 0.0\n\n    with torch.no_grad():\n        for imgs, masks in val_loader:\n            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n            outputs = model(imgs)\n            val_miou += compute_miou_batch(outputs, masks, NUM_CLASSES).item()\n\n    val_miou /= len(val_loader)\n\n    # Step scheduler\n    scheduler.step(val_miou)\n    current_lr = optimizer.param_groups[0][\"lr\"]\n\n    print(\n        f\"Epoch [{epoch+1}/{num_epochs}] | \"\n        f\"Train Loss: {train_loss:.4f} | \"\n        f\"Val mIoU: {val_miou:.4f} | \"\n        f\"LR: {current_lr:.2e}\"\n    )\n\n    # -------- EARLY STOPPING --------\n    if val_miou > best_miou:\n        best_miou = val_miou\n        torch.save(model.state_dict(), \"/kaggle/working/best_model.pth\")\n        epochs_no_improve = 0\n        print(\" Best model saved\")\n    else:\n        epochs_no_improve += 1\n        print(f\" No improvement ({epochs_no_improve}/{patience})\")\n\n    if epochs_no_improve >= patience:\n        print(\" Early stopping triggered\")\n        break\n\n# Save last model (backup)\ntorch.save(model.state_dict(), \"/kaggle/working/last_model.pth\")\n\nprint(\"\\n Training finished\")\nprint(f\" Best mIoU: {best_miou:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T10:58:45.045008Z","iopub.execute_input":"2025-12-29T10:58:45.045229Z","iopub.status.idle":"2025-12-29T12:03:43.130636Z","shell.execute_reply.started":"2025-12-29T10:58:45.045208Z","shell.execute_reply":"2025-12-29T12:03:43.129945Z"}},"outputs":[{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 97.8M/97.8M [00:00<00:00, 213MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/50] | Train Loss: 2.0413 | Val mIoU: 0.2738 | LR: 3.00e-04\n Best model saved\nEpoch [2/50] | Train Loss: 1.7091 | Val mIoU: 0.3467 | LR: 3.00e-04\n Best model saved\nEpoch [3/50] | Train Loss: 1.6076 | Val mIoU: 0.3356 | LR: 3.00e-04\n No improvement (1/5)\nEpoch [4/50] | Train Loss: 1.5076 | Val mIoU: 0.3271 | LR: 3.00e-04\n No improvement (2/5)\nEpoch [5/50] | Train Loss: 1.4589 | Val mIoU: 0.3559 | LR: 3.00e-04\n Best model saved\nEpoch [6/50] | Train Loss: 1.3834 | Val mIoU: 0.3546 | LR: 3.00e-04\n No improvement (1/5)\nEpoch [7/50] | Train Loss: 1.3611 | Val mIoU: 0.3789 | LR: 3.00e-04\n Best model saved\nEpoch [8/50] | Train Loss: 1.3460 | Val mIoU: 0.3987 | LR: 3.00e-04\n Best model saved\nEpoch [9/50] | Train Loss: 1.3055 | Val mIoU: 0.3628 | LR: 3.00e-04\n No improvement (1/5)\nEpoch [10/50] | Train Loss: 1.2798 | Val mIoU: 0.4129 | LR: 3.00e-04\n Best model saved\nEpoch [11/50] | Train Loss: 1.2316 | Val mIoU: 0.4040 | LR: 3.00e-04\n No improvement (1/5)\nEpoch [12/50] | Train Loss: 1.2415 | Val mIoU: 0.3978 | LR: 3.00e-04\n No improvement (2/5)\nEpoch [13/50] | Train Loss: 1.1760 | Val mIoU: 0.4534 | LR: 3.00e-04\n Best model saved\nEpoch [14/50] | Train Loss: 1.1316 | Val mIoU: 0.4927 | LR: 3.00e-04\n Best model saved\nEpoch [15/50] | Train Loss: 1.1104 | Val mIoU: 0.4721 | LR: 3.00e-04\n No improvement (1/5)\nEpoch [16/50] | Train Loss: 1.0636 | Val mIoU: 0.4316 | LR: 3.00e-04\n No improvement (2/5)\nEpoch [17/50] | Train Loss: 1.0235 | Val mIoU: 0.4614 | LR: 1.50e-04\n No improvement (3/5)\nEpoch [18/50] | Train Loss: 0.9345 | Val mIoU: 0.5074 | LR: 1.50e-04\n Best model saved\nEpoch [19/50] | Train Loss: 0.9032 | Val mIoU: 0.4980 | LR: 1.50e-04\n No improvement (1/5)\nEpoch [20/50] | Train Loss: 0.8723 | Val mIoU: 0.5507 | LR: 1.50e-04\n Best model saved\nEpoch [21/50] | Train Loss: 0.8540 | Val mIoU: 0.5280 | LR: 1.50e-04\n No improvement (1/5)\nEpoch [22/50] | Train Loss: 0.8294 | Val mIoU: 0.5299 | LR: 1.50e-04\n No improvement (2/5)\nEpoch [23/50] | Train Loss: 0.7953 | Val mIoU: 0.5357 | LR: 7.50e-05\n No improvement (3/5)\nEpoch [24/50] | Train Loss: 0.7413 | Val mIoU: 0.5462 | LR: 7.50e-05\n No improvement (4/5)\nEpoch [25/50] | Train Loss: 0.7351 | Val mIoU: 0.5387 | LR: 7.50e-05\n No improvement (5/5)\n Early stopping triggered\n\n Training finished\n Best mIoU: 0.5507\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"## Model Saving\n","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/finall_model.pth\")\nprint(\"Training finished\")\nprint(\"Best mIoU:\", best_miou)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T12:03:43.131923Z","iopub.execute_input":"2025-12-29T12:03:43.132198Z","iopub.status.idle":"2025-12-29T12:03:43.381443Z","shell.execute_reply.started":"2025-12-29T12:03:43.132158Z","shell.execute_reply":"2025-12-29T12:03:43.380847Z"}},"outputs":[{"name":"stdout","text":"Training finished\nBest mIoU: 0.5506737354923698\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Validation & Test Evaluation\n","metadata":{}},{"cell_type":"code","source":"def evaluate_miou(model, dataloader, num_classes):\n    model.eval()\n    total_miou = 0.0\n\n    with torch.no_grad():\n        for imgs, masks in tqdm(dataloader, desc=\"Validating\"):\n            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n            outputs = model(imgs)\n\n            total_miou += compute_miou_batch(outputs, masks, num_classes).item()\n\n    return total_miou / len(dataloader)\n\nval_miou = evaluate_miou(model, val_loader, NUM_CLASSES)\nprint(f\"Validation mIoU: {val_miou:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T12:03:43.382325Z","iopub.execute_input":"2025-12-29T12:03:43.382590Z","iopub.status.idle":"2025-12-29T12:03:56.882431Z","shell.execute_reply.started":"2025-12-29T12:03:43.382566Z","shell.execute_reply":"2025-12-29T12:03:56.881697Z"}},"outputs":[{"name":"stderr","text":"Validating: 100%|██████████| 85/85 [00:13<00:00,  6.30it/s]","output_type":"stream"},{"name":"stdout","text":"Validation mIoU: 0.5387\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def per_class_iou(model, dataloader, num_classes):\n    model.eval()\n    inter = torch.zeros(num_classes).to(DEVICE)\n    union = torch.zeros(num_classes).to(DEVICE)\n\n    with torch.no_grad():\n        for imgs, masks in tqdm(dataloader, desc=\"Per-class IoU\"):\n            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)\n            preds = torch.argmax(model(imgs), dim=1)\n\n            for c in range(num_classes):\n                inter[c] += ((preds == c) & (masks == c)).sum()\n                union[c] += ((preds == c) | (masks == c)).sum()\n\n    iou = inter / (union + 1e-6)\n    return iou.cpu().numpy()\n\niou_per_class = per_class_iou(model, val_loader, NUM_CLASSES)\n\nfor idx, val in enumerate(iou_per_class):\n    print(f\"{idx}: IoU = {val:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T12:03:56.883608Z","iopub.execute_input":"2025-12-29T12:03:56.883885Z","iopub.status.idle":"2025-12-29T12:04:10.078446Z","shell.execute_reply.started":"2025-12-29T12:03:56.883856Z","shell.execute_reply":"2025-12-29T12:04:10.077628Z"}},"outputs":[{"name":"stderr","text":"Per-class IoU: 100%|██████████| 85/85 [00:13<00:00,  6.46it/s]","output_type":"stream"},{"name":"stdout","text":"0: IoU = 0.7293\n1: IoU = 0.7502\n2: IoU = 0.7203\n3: IoU = 0.6236\n4: IoU = 0.6793\n5: IoU = 0.6222\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"test_ds = OilSpillDataset(ROOT, \"test\", val_transforms)\n\ntest_loader = DataLoader(\n    test_ds,\n    batch_size=8,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)\n\nprint(\"Test samples:\", len(test_ds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T12:04:10.080356Z","iopub.execute_input":"2025-12-29T12:04:10.080684Z","iopub.status.idle":"2025-12-29T12:04:10.214332Z","shell.execute_reply.started":"2025-12-29T12:04:10.080653Z","shell.execute_reply":"2025-12-29T12:04:10.213607Z"}},"outputs":[{"name":"stdout","text":"[TEST] 343 samples loaded\nTest samples: 343\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"test_miou = evaluate_miou(model, test_loader, NUM_CLASSES)\nprint(f\"Test mIoU: {test_miou:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-29T12:04:10.215399Z","iopub.execute_input":"2025-12-29T12:04:10.215875Z","iopub.status.idle":"2025-12-29T12:04:17.363636Z","shell.execute_reply.started":"2025-12-29T12:04:10.215842Z","shell.execute_reply":"2025-12-29T12:04:17.362739Z"}},"outputs":[{"name":"stderr","text":"Validating: 100%|██████████| 43/43 [00:07<00:00,  6.02it/s]","output_type":"stream"},{"name":"stdout","text":"Test mIoU: 0.5611\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":17}]}